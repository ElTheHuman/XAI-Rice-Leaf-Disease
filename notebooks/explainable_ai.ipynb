{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install matplotlib\n",
    "# %pip install tensorflow==2.14.0\n",
    "# %pip install innvestigate==2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the architecture that was made before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:883: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
    "base_model.trainable=False\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "output_layer = Dense(9, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the saved weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../src/models/dense_net_model_weight.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPaddin  (None, 262, 262, 3)          0         ['input_1[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1/conv (Conv2D)         (None, 128, 128, 64)         9408      ['zero_padding2d[0][0]']      \n",
      "                                                                                                  \n",
      " conv1/bn (BatchNormalizati  (None, 128, 128, 64)         256       ['conv1/conv[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv1/relu (Activation)     (None, 128, 128, 64)         0         ['conv1/bn[0][0]']            \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadd  (None, 130, 130, 64)         0         ['conv1/relu[0][0]']          \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)        (None, 64, 64, 64)           0         ['zero_padding2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNo  (None, 64, 64, 64)           256       ['pool1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_0_relu (Activ  (None, 64, 64, 64)           0         ['conv2_block1_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 64, 64, 128)          8192      ['conv2_block1_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 64, 64, 128)          512       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 64, 64, 128)          0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 64, 64, 32)           36864     ['conv2_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_concat (Conca  (None, 64, 64, 96)           0         ['pool1[0][0]',               \n",
      " tenate)                                                             'conv2_block1_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block2_0_bn (BatchNo  (None, 64, 64, 96)           384       ['conv2_block1_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_0_relu (Activ  (None, 64, 64, 96)           0         ['conv2_block2_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 64, 64, 128)          12288     ['conv2_block2_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 64, 64, 128)          512       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 64, 64, 128)          0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 64, 64, 32)           36864     ['conv2_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_concat (Conca  (None, 64, 64, 128)          0         ['conv2_block1_concat[0][0]', \n",
      " tenate)                                                             'conv2_block2_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block3_0_bn (BatchNo  (None, 64, 64, 128)          512       ['conv2_block2_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_0_relu (Activ  (None, 64, 64, 128)          0         ['conv2_block3_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 64, 64, 128)          16384     ['conv2_block3_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 64, 64, 128)          512       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 64, 64, 128)          0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 64, 64, 32)           36864     ['conv2_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_concat (Conca  (None, 64, 64, 160)          0         ['conv2_block2_concat[0][0]', \n",
      " tenate)                                                             'conv2_block3_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block4_0_bn (BatchNo  (None, 64, 64, 160)          640       ['conv2_block3_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block4_0_relu (Activ  (None, 64, 64, 160)          0         ['conv2_block4_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block4_1_conv (Conv2  (None, 64, 64, 128)          20480     ['conv2_block4_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_1_bn (BatchNo  (None, 64, 64, 128)          512       ['conv2_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block4_1_relu (Activ  (None, 64, 64, 128)          0         ['conv2_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block4_2_conv (Conv2  (None, 64, 64, 32)           36864     ['conv2_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_concat (Conca  (None, 64, 64, 192)          0         ['conv2_block3_concat[0][0]', \n",
      " tenate)                                                             'conv2_block4_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block5_0_bn (BatchNo  (None, 64, 64, 192)          768       ['conv2_block4_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block5_0_relu (Activ  (None, 64, 64, 192)          0         ['conv2_block5_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block5_1_conv (Conv2  (None, 64, 64, 128)          24576     ['conv2_block5_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_1_bn (BatchNo  (None, 64, 64, 128)          512       ['conv2_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block5_1_relu (Activ  (None, 64, 64, 128)          0         ['conv2_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block5_2_conv (Conv2  (None, 64, 64, 32)           36864     ['conv2_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_concat (Conca  (None, 64, 64, 224)          0         ['conv2_block4_concat[0][0]', \n",
      " tenate)                                                             'conv2_block5_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block6_0_bn (BatchNo  (None, 64, 64, 224)          896       ['conv2_block5_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block6_0_relu (Activ  (None, 64, 64, 224)          0         ['conv2_block6_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block6_1_conv (Conv2  (None, 64, 64, 128)          28672     ['conv2_block6_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_1_bn (BatchNo  (None, 64, 64, 128)          512       ['conv2_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block6_1_relu (Activ  (None, 64, 64, 128)          0         ['conv2_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block6_2_conv (Conv2  (None, 64, 64, 32)           36864     ['conv2_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_concat (Conca  (None, 64, 64, 256)          0         ['conv2_block5_concat[0][0]', \n",
      " tenate)                                                             'conv2_block6_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " pool2_bn (BatchNormalizati  (None, 64, 64, 256)          1024      ['conv2_block6_concat[0][0]'] \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " pool2_relu (Activation)     (None, 64, 64, 256)          0         ['pool2_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool2_conv (Conv2D)         (None, 64, 64, 128)          32768     ['pool2_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool2_pool (AveragePooling  (None, 32, 32, 128)          0         ['pool2_conv[0][0]']          \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNo  (None, 32, 32, 128)          512       ['pool2_pool[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_0_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block1_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 32, 32, 128)          16384     ['conv3_block1_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 32, 32, 32)           36864     ['conv3_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_concat (Conca  (None, 32, 32, 160)          0         ['pool2_pool[0][0]',          \n",
      " tenate)                                                             'conv3_block1_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block2_0_bn (BatchNo  (None, 32, 32, 160)          640       ['conv3_block1_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_0_relu (Activ  (None, 32, 32, 160)          0         ['conv3_block2_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 32, 32, 128)          20480     ['conv3_block2_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 32, 32, 32)           36864     ['conv3_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_concat (Conca  (None, 32, 32, 192)          0         ['conv3_block1_concat[0][0]', \n",
      " tenate)                                                             'conv3_block2_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block3_0_bn (BatchNo  (None, 32, 32, 192)          768       ['conv3_block2_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_0_relu (Activ  (None, 32, 32, 192)          0         ['conv3_block3_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 32, 32, 128)          24576     ['conv3_block3_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 32, 32, 32)           36864     ['conv3_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_concat (Conca  (None, 32, 32, 224)          0         ['conv3_block2_concat[0][0]', \n",
      " tenate)                                                             'conv3_block3_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block4_0_bn (BatchNo  (None, 32, 32, 224)          896       ['conv3_block3_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_0_relu (Activ  (None, 32, 32, 224)          0         ['conv3_block4_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 32, 32, 128)          28672     ['conv3_block4_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 32, 32, 32)           36864     ['conv3_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_concat (Conca  (None, 32, 32, 256)          0         ['conv3_block3_concat[0][0]', \n",
      " tenate)                                                             'conv3_block4_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block5_0_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv3_block4_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block5_0_relu (Activ  (None, 32, 32, 256)          0         ['conv3_block5_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block5_1_conv (Conv2  (None, 32, 32, 128)          32768     ['conv3_block5_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_1_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block5_1_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block5_2_conv (Conv2  (None, 32, 32, 32)           36864     ['conv3_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_concat (Conca  (None, 32, 32, 288)          0         ['conv3_block4_concat[0][0]', \n",
      " tenate)                                                             'conv3_block5_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block6_0_bn (BatchNo  (None, 32, 32, 288)          1152      ['conv3_block5_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block6_0_relu (Activ  (None, 32, 32, 288)          0         ['conv3_block6_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block6_1_conv (Conv2  (None, 32, 32, 128)          36864     ['conv3_block6_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_1_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block6_1_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block6_2_conv (Conv2  (None, 32, 32, 32)           36864     ['conv3_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_concat (Conca  (None, 32, 32, 320)          0         ['conv3_block5_concat[0][0]', \n",
      " tenate)                                                             'conv3_block6_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block7_0_bn (BatchNo  (None, 32, 32, 320)          1280      ['conv3_block6_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block7_0_relu (Activ  (None, 32, 32, 320)          0         ['conv3_block7_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block7_1_conv (Conv2  (None, 32, 32, 128)          40960     ['conv3_block7_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_1_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block7_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block7_1_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block7_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block7_2_conv (Conv2  (None, 32, 32, 32)           36864     ['conv3_block7_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_concat (Conca  (None, 32, 32, 352)          0         ['conv3_block6_concat[0][0]', \n",
      " tenate)                                                             'conv3_block7_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block8_0_bn (BatchNo  (None, 32, 32, 352)          1408      ['conv3_block7_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block8_0_relu (Activ  (None, 32, 32, 352)          0         ['conv3_block8_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block8_1_conv (Conv2  (None, 32, 32, 128)          45056     ['conv3_block8_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_1_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block8_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block8_1_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block8_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block8_2_conv (Conv2  (None, 32, 32, 32)           36864     ['conv3_block8_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_concat (Conca  (None, 32, 32, 384)          0         ['conv3_block7_concat[0][0]', \n",
      " tenate)                                                             'conv3_block8_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block9_0_bn (BatchNo  (None, 32, 32, 384)          1536      ['conv3_block8_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block9_0_relu (Activ  (None, 32, 32, 384)          0         ['conv3_block9_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block9_1_conv (Conv2  (None, 32, 32, 128)          49152     ['conv3_block9_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_1_bn (BatchNo  (None, 32, 32, 128)          512       ['conv3_block9_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block9_1_relu (Activ  (None, 32, 32, 128)          0         ['conv3_block9_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block9_2_conv (Conv2  (None, 32, 32, 32)           36864     ['conv3_block9_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_concat (Conca  (None, 32, 32, 416)          0         ['conv3_block8_concat[0][0]', \n",
      " tenate)                                                             'conv3_block9_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block10_0_bn (BatchN  (None, 32, 32, 416)          1664      ['conv3_block9_concat[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block10_0_relu (Acti  (None, 32, 32, 416)          0         ['conv3_block10_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block10_1_conv (Conv  (None, 32, 32, 128)          53248     ['conv3_block10_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_1_bn (BatchN  (None, 32, 32, 128)          512       ['conv3_block10_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block10_1_relu (Acti  (None, 32, 32, 128)          0         ['conv3_block10_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block10_2_conv (Conv  (None, 32, 32, 32)           36864     ['conv3_block10_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_concat (Conc  (None, 32, 32, 448)          0         ['conv3_block9_concat[0][0]', \n",
      " atenate)                                                            'conv3_block10_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv3_block11_0_bn (BatchN  (None, 32, 32, 448)          1792      ['conv3_block10_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block11_0_relu (Acti  (None, 32, 32, 448)          0         ['conv3_block11_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block11_1_conv (Conv  (None, 32, 32, 128)          57344     ['conv3_block11_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_1_bn (BatchN  (None, 32, 32, 128)          512       ['conv3_block11_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block11_1_relu (Acti  (None, 32, 32, 128)          0         ['conv3_block11_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block11_2_conv (Conv  (None, 32, 32, 32)           36864     ['conv3_block11_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_concat (Conc  (None, 32, 32, 480)          0         ['conv3_block10_concat[0][0]',\n",
      " atenate)                                                            'conv3_block11_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv3_block12_0_bn (BatchN  (None, 32, 32, 480)          1920      ['conv3_block11_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block12_0_relu (Acti  (None, 32, 32, 480)          0         ['conv3_block12_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block12_1_conv (Conv  (None, 32, 32, 128)          61440     ['conv3_block12_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_1_bn (BatchN  (None, 32, 32, 128)          512       ['conv3_block12_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block12_1_relu (Acti  (None, 32, 32, 128)          0         ['conv3_block12_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block12_2_conv (Conv  (None, 32, 32, 32)           36864     ['conv3_block12_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_concat (Conc  (None, 32, 32, 512)          0         ['conv3_block11_concat[0][0]',\n",
      " atenate)                                                            'conv3_block12_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " pool3_bn (BatchNormalizati  (None, 32, 32, 512)          2048      ['conv3_block12_concat[0][0]']\n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " pool3_relu (Activation)     (None, 32, 32, 512)          0         ['pool3_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool3_conv (Conv2D)         (None, 32, 32, 256)          131072    ['pool3_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool3_pool (AveragePooling  (None, 16, 16, 256)          0         ['pool3_conv[0][0]']          \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNo  (None, 16, 16, 256)          1024      ['pool3_pool[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_0_relu (Activ  (None, 16, 16, 256)          0         ['conv4_block1_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 16, 16, 128)          32768     ['conv4_block1_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 16, 16, 128)          0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 16, 16, 32)           36864     ['conv4_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_concat (Conca  (None, 16, 16, 288)          0         ['pool3_pool[0][0]',          \n",
      " tenate)                                                             'conv4_block1_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block2_0_bn (BatchNo  (None, 16, 16, 288)          1152      ['conv4_block1_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_0_relu (Activ  (None, 16, 16, 288)          0         ['conv4_block2_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 16, 16, 128)          36864     ['conv4_block2_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 16, 16, 128)          0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 16, 16, 32)           36864     ['conv4_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_concat (Conca  (None, 16, 16, 320)          0         ['conv4_block1_concat[0][0]', \n",
      " tenate)                                                             'conv4_block2_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block3_0_bn (BatchNo  (None, 16, 16, 320)          1280      ['conv4_block2_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_0_relu (Activ  (None, 16, 16, 320)          0         ['conv4_block3_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 16, 16, 128)          40960     ['conv4_block3_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 16, 16, 128)          0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 16, 16, 32)           36864     ['conv4_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_concat (Conca  (None, 16, 16, 352)          0         ['conv4_block2_concat[0][0]', \n",
      " tenate)                                                             'conv4_block3_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block4_0_bn (BatchNo  (None, 16, 16, 352)          1408      ['conv4_block3_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_0_relu (Activ  (None, 16, 16, 352)          0         ['conv4_block4_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 16, 16, 128)          45056     ['conv4_block4_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 16, 16, 128)          0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 16, 16, 32)           36864     ['conv4_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_concat (Conca  (None, 16, 16, 384)          0         ['conv4_block3_concat[0][0]', \n",
      " tenate)                                                             'conv4_block4_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block5_0_bn (BatchNo  (None, 16, 16, 384)          1536      ['conv4_block4_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_0_relu (Activ  (None, 16, 16, 384)          0         ['conv4_block5_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 16, 16, 128)          49152     ['conv4_block5_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 16, 16, 128)          0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 16, 16, 32)           36864     ['conv4_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_concat (Conca  (None, 16, 16, 416)          0         ['conv4_block4_concat[0][0]', \n",
      " tenate)                                                             'conv4_block5_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block6_0_bn (BatchNo  (None, 16, 16, 416)          1664      ['conv4_block5_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_0_relu (Activ  (None, 16, 16, 416)          0         ['conv4_block6_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 16, 16, 128)          53248     ['conv4_block6_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 16, 16, 128)          0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 16, 16, 32)           36864     ['conv4_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_concat (Conca  (None, 16, 16, 448)          0         ['conv4_block5_concat[0][0]', \n",
      " tenate)                                                             'conv4_block6_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block7_0_bn (BatchNo  (None, 16, 16, 448)          1792      ['conv4_block6_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block7_0_relu (Activ  (None, 16, 16, 448)          0         ['conv4_block7_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block7_1_conv (Conv2  (None, 16, 16, 128)          57344     ['conv4_block7_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv4_block7_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block7_1_relu (Activ  (None, 16, 16, 128)          0         ['conv4_block7_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block7_2_conv (Conv2  (None, 16, 16, 32)           36864     ['conv4_block7_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_concat (Conca  (None, 16, 16, 480)          0         ['conv4_block6_concat[0][0]', \n",
      " tenate)                                                             'conv4_block7_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block8_0_bn (BatchNo  (None, 16, 16, 480)          1920      ['conv4_block7_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block8_0_relu (Activ  (None, 16, 16, 480)          0         ['conv4_block8_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block8_1_conv (Conv2  (None, 16, 16, 128)          61440     ['conv4_block8_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv4_block8_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block8_1_relu (Activ  (None, 16, 16, 128)          0         ['conv4_block8_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block8_2_conv (Conv2  (None, 16, 16, 32)           36864     ['conv4_block8_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_concat (Conca  (None, 16, 16, 512)          0         ['conv4_block7_concat[0][0]', \n",
      " tenate)                                                             'conv4_block8_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block9_0_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv4_block8_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block9_0_relu (Activ  (None, 16, 16, 512)          0         ['conv4_block9_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block9_1_conv (Conv2  (None, 16, 16, 128)          65536     ['conv4_block9_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv4_block9_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block9_1_relu (Activ  (None, 16, 16, 128)          0         ['conv4_block9_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block9_2_conv (Conv2  (None, 16, 16, 32)           36864     ['conv4_block9_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_concat (Conca  (None, 16, 16, 544)          0         ['conv4_block8_concat[0][0]', \n",
      " tenate)                                                             'conv4_block9_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block10_0_bn (BatchN  (None, 16, 16, 544)          2176      ['conv4_block9_concat[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block10_0_relu (Acti  (None, 16, 16, 544)          0         ['conv4_block10_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block10_1_conv (Conv  (None, 16, 16, 128)          69632     ['conv4_block10_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block10_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block10_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block10_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block10_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block10_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_concat (Conc  (None, 16, 16, 576)          0         ['conv4_block9_concat[0][0]', \n",
      " atenate)                                                            'conv4_block10_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block11_0_bn (BatchN  (None, 16, 16, 576)          2304      ['conv4_block10_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block11_0_relu (Acti  (None, 16, 16, 576)          0         ['conv4_block11_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block11_1_conv (Conv  (None, 16, 16, 128)          73728     ['conv4_block11_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block11_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block11_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block11_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block11_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block11_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_concat (Conc  (None, 16, 16, 608)          0         ['conv4_block10_concat[0][0]',\n",
      " atenate)                                                            'conv4_block11_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block12_0_bn (BatchN  (None, 16, 16, 608)          2432      ['conv4_block11_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block12_0_relu (Acti  (None, 16, 16, 608)          0         ['conv4_block12_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block12_1_conv (Conv  (None, 16, 16, 128)          77824     ['conv4_block12_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block12_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block12_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block12_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block12_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block12_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_concat (Conc  (None, 16, 16, 640)          0         ['conv4_block11_concat[0][0]',\n",
      " atenate)                                                            'conv4_block12_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block13_0_bn (BatchN  (None, 16, 16, 640)          2560      ['conv4_block12_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block13_0_relu (Acti  (None, 16, 16, 640)          0         ['conv4_block13_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block13_1_conv (Conv  (None, 16, 16, 128)          81920     ['conv4_block13_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block13_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block13_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block13_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block13_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block13_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_concat (Conc  (None, 16, 16, 672)          0         ['conv4_block12_concat[0][0]',\n",
      " atenate)                                                            'conv4_block13_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block14_0_bn (BatchN  (None, 16, 16, 672)          2688      ['conv4_block13_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block14_0_relu (Acti  (None, 16, 16, 672)          0         ['conv4_block14_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block14_1_conv (Conv  (None, 16, 16, 128)          86016     ['conv4_block14_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block14_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block14_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block14_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block14_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block14_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_concat (Conc  (None, 16, 16, 704)          0         ['conv4_block13_concat[0][0]',\n",
      " atenate)                                                            'conv4_block14_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block15_0_bn (BatchN  (None, 16, 16, 704)          2816      ['conv4_block14_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block15_0_relu (Acti  (None, 16, 16, 704)          0         ['conv4_block15_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block15_1_conv (Conv  (None, 16, 16, 128)          90112     ['conv4_block15_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block15_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block15_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block15_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block15_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block15_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_concat (Conc  (None, 16, 16, 736)          0         ['conv4_block14_concat[0][0]',\n",
      " atenate)                                                            'conv4_block15_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block16_0_bn (BatchN  (None, 16, 16, 736)          2944      ['conv4_block15_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block16_0_relu (Acti  (None, 16, 16, 736)          0         ['conv4_block16_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block16_1_conv (Conv  (None, 16, 16, 128)          94208     ['conv4_block16_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block16_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block16_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block16_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block16_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block16_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_concat (Conc  (None, 16, 16, 768)          0         ['conv4_block15_concat[0][0]',\n",
      " atenate)                                                            'conv4_block16_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block17_0_bn (BatchN  (None, 16, 16, 768)          3072      ['conv4_block16_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block17_0_relu (Acti  (None, 16, 16, 768)          0         ['conv4_block17_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block17_1_conv (Conv  (None, 16, 16, 128)          98304     ['conv4_block17_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block17_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block17_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block17_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block17_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block17_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_concat (Conc  (None, 16, 16, 800)          0         ['conv4_block16_concat[0][0]',\n",
      " atenate)                                                            'conv4_block17_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block18_0_bn (BatchN  (None, 16, 16, 800)          3200      ['conv4_block17_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block18_0_relu (Acti  (None, 16, 16, 800)          0         ['conv4_block18_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block18_1_conv (Conv  (None, 16, 16, 128)          102400    ['conv4_block18_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block18_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block18_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block18_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block18_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block18_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_concat (Conc  (None, 16, 16, 832)          0         ['conv4_block17_concat[0][0]',\n",
      " atenate)                                                            'conv4_block18_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block19_0_bn (BatchN  (None, 16, 16, 832)          3328      ['conv4_block18_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block19_0_relu (Acti  (None, 16, 16, 832)          0         ['conv4_block19_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block19_1_conv (Conv  (None, 16, 16, 128)          106496    ['conv4_block19_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block19_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block19_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block19_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block19_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block19_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_concat (Conc  (None, 16, 16, 864)          0         ['conv4_block18_concat[0][0]',\n",
      " atenate)                                                            'conv4_block19_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block20_0_bn (BatchN  (None, 16, 16, 864)          3456      ['conv4_block19_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block20_0_relu (Acti  (None, 16, 16, 864)          0         ['conv4_block20_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block20_1_conv (Conv  (None, 16, 16, 128)          110592    ['conv4_block20_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block20_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block20_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block20_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block20_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block20_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_concat (Conc  (None, 16, 16, 896)          0         ['conv4_block19_concat[0][0]',\n",
      " atenate)                                                            'conv4_block20_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block21_0_bn (BatchN  (None, 16, 16, 896)          3584      ['conv4_block20_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block21_0_relu (Acti  (None, 16, 16, 896)          0         ['conv4_block21_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block21_1_conv (Conv  (None, 16, 16, 128)          114688    ['conv4_block21_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block21_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block21_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block21_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block21_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block21_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_concat (Conc  (None, 16, 16, 928)          0         ['conv4_block20_concat[0][0]',\n",
      " atenate)                                                            'conv4_block21_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block22_0_bn (BatchN  (None, 16, 16, 928)          3712      ['conv4_block21_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block22_0_relu (Acti  (None, 16, 16, 928)          0         ['conv4_block22_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block22_1_conv (Conv  (None, 16, 16, 128)          118784    ['conv4_block22_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block22_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block22_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block22_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block22_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block22_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_concat (Conc  (None, 16, 16, 960)          0         ['conv4_block21_concat[0][0]',\n",
      " atenate)                                                            'conv4_block22_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block23_0_bn (BatchN  (None, 16, 16, 960)          3840      ['conv4_block22_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block23_0_relu (Acti  (None, 16, 16, 960)          0         ['conv4_block23_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block23_1_conv (Conv  (None, 16, 16, 128)          122880    ['conv4_block23_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block23_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block23_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block23_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block23_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block23_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_concat (Conc  (None, 16, 16, 992)          0         ['conv4_block22_concat[0][0]',\n",
      " atenate)                                                            'conv4_block23_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv4_block24_0_bn (BatchN  (None, 16, 16, 992)          3968      ['conv4_block23_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block24_0_relu (Acti  (None, 16, 16, 992)          0         ['conv4_block24_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block24_1_conv (Conv  (None, 16, 16, 128)          126976    ['conv4_block24_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_1_bn (BatchN  (None, 16, 16, 128)          512       ['conv4_block24_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block24_1_relu (Acti  (None, 16, 16, 128)          0         ['conv4_block24_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block24_2_conv (Conv  (None, 16, 16, 32)           36864     ['conv4_block24_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_concat (Conc  (None, 16, 16, 1024)         0         ['conv4_block23_concat[0][0]',\n",
      " atenate)                                                            'conv4_block24_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " pool4_bn (BatchNormalizati  (None, 16, 16, 1024)         4096      ['conv4_block24_concat[0][0]']\n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " pool4_relu (Activation)     (None, 16, 16, 1024)         0         ['pool4_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool4_conv (Conv2D)         (None, 16, 16, 512)          524288    ['pool4_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool4_pool (AveragePooling  (None, 8, 8, 512)            0         ['pool4_conv[0][0]']          \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNo  (None, 8, 8, 512)            2048      ['pool4_pool[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_0_relu (Activ  (None, 8, 8, 512)            0         ['conv5_block1_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, 8, 8, 128)            65536     ['conv5_block1_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, 8, 8, 128)            0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, 8, 8, 32)             36864     ['conv5_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_concat (Conca  (None, 8, 8, 544)            0         ['pool4_pool[0][0]',          \n",
      " tenate)                                                             'conv5_block1_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block2_0_bn (BatchNo  (None, 8, 8, 544)            2176      ['conv5_block1_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_0_relu (Activ  (None, 8, 8, 544)            0         ['conv5_block2_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, 8, 8, 128)            69632     ['conv5_block2_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, 8, 8, 128)            0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, 8, 8, 32)             36864     ['conv5_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_concat (Conca  (None, 8, 8, 576)            0         ['conv5_block1_concat[0][0]', \n",
      " tenate)                                                             'conv5_block2_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block3_0_bn (BatchNo  (None, 8, 8, 576)            2304      ['conv5_block2_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_0_relu (Activ  (None, 8, 8, 576)            0         ['conv5_block3_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, 8, 8, 128)            73728     ['conv5_block3_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, 8, 8, 128)            0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, 8, 8, 32)             36864     ['conv5_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_concat (Conca  (None, 8, 8, 608)            0         ['conv5_block2_concat[0][0]', \n",
      " tenate)                                                             'conv5_block3_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block4_0_bn (BatchNo  (None, 8, 8, 608)            2432      ['conv5_block3_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block4_0_relu (Activ  (None, 8, 8, 608)            0         ['conv5_block4_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block4_1_conv (Conv2  (None, 8, 8, 128)            77824     ['conv5_block4_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv5_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block4_1_relu (Activ  (None, 8, 8, 128)            0         ['conv5_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block4_2_conv (Conv2  (None, 8, 8, 32)             36864     ['conv5_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_concat (Conca  (None, 8, 8, 640)            0         ['conv5_block3_concat[0][0]', \n",
      " tenate)                                                             'conv5_block4_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block5_0_bn (BatchNo  (None, 8, 8, 640)            2560      ['conv5_block4_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block5_0_relu (Activ  (None, 8, 8, 640)            0         ['conv5_block5_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block5_1_conv (Conv2  (None, 8, 8, 128)            81920     ['conv5_block5_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv5_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block5_1_relu (Activ  (None, 8, 8, 128)            0         ['conv5_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block5_2_conv (Conv2  (None, 8, 8, 32)             36864     ['conv5_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_concat (Conca  (None, 8, 8, 672)            0         ['conv5_block4_concat[0][0]', \n",
      " tenate)                                                             'conv5_block5_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block6_0_bn (BatchNo  (None, 8, 8, 672)            2688      ['conv5_block5_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block6_0_relu (Activ  (None, 8, 8, 672)            0         ['conv5_block6_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block6_1_conv (Conv2  (None, 8, 8, 128)            86016     ['conv5_block6_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv5_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block6_1_relu (Activ  (None, 8, 8, 128)            0         ['conv5_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block6_2_conv (Conv2  (None, 8, 8, 32)             36864     ['conv5_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_concat (Conca  (None, 8, 8, 704)            0         ['conv5_block5_concat[0][0]', \n",
      " tenate)                                                             'conv5_block6_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block7_0_bn (BatchNo  (None, 8, 8, 704)            2816      ['conv5_block6_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block7_0_relu (Activ  (None, 8, 8, 704)            0         ['conv5_block7_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block7_1_conv (Conv2  (None, 8, 8, 128)            90112     ['conv5_block7_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv5_block7_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block7_1_relu (Activ  (None, 8, 8, 128)            0         ['conv5_block7_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block7_2_conv (Conv2  (None, 8, 8, 32)             36864     ['conv5_block7_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_concat (Conca  (None, 8, 8, 736)            0         ['conv5_block6_concat[0][0]', \n",
      " tenate)                                                             'conv5_block7_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block8_0_bn (BatchNo  (None, 8, 8, 736)            2944      ['conv5_block7_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block8_0_relu (Activ  (None, 8, 8, 736)            0         ['conv5_block8_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block8_1_conv (Conv2  (None, 8, 8, 128)            94208     ['conv5_block8_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv5_block8_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block8_1_relu (Activ  (None, 8, 8, 128)            0         ['conv5_block8_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block8_2_conv (Conv2  (None, 8, 8, 32)             36864     ['conv5_block8_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_concat (Conca  (None, 8, 8, 768)            0         ['conv5_block7_concat[0][0]', \n",
      " tenate)                                                             'conv5_block8_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block9_0_bn (BatchNo  (None, 8, 8, 768)            3072      ['conv5_block8_concat[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block9_0_relu (Activ  (None, 8, 8, 768)            0         ['conv5_block9_0_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block9_1_conv (Conv2  (None, 8, 8, 128)            98304     ['conv5_block9_0_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_1_bn (BatchNo  (None, 8, 8, 128)            512       ['conv5_block9_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block9_1_relu (Activ  (None, 8, 8, 128)            0         ['conv5_block9_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block9_2_conv (Conv2  (None, 8, 8, 32)             36864     ['conv5_block9_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_concat (Conca  (None, 8, 8, 800)            0         ['conv5_block8_concat[0][0]', \n",
      " tenate)                                                             'conv5_block9_2_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block10_0_bn (BatchN  (None, 8, 8, 800)            3200      ['conv5_block9_concat[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block10_0_relu (Acti  (None, 8, 8, 800)            0         ['conv5_block10_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block10_1_conv (Conv  (None, 8, 8, 128)            102400    ['conv5_block10_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_1_bn (BatchN  (None, 8, 8, 128)            512       ['conv5_block10_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block10_1_relu (Acti  (None, 8, 8, 128)            0         ['conv5_block10_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block10_2_conv (Conv  (None, 8, 8, 32)             36864     ['conv5_block10_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_concat (Conc  (None, 8, 8, 832)            0         ['conv5_block9_concat[0][0]', \n",
      " atenate)                                                            'conv5_block10_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv5_block11_0_bn (BatchN  (None, 8, 8, 832)            3328      ['conv5_block10_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block11_0_relu (Acti  (None, 8, 8, 832)            0         ['conv5_block11_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block11_1_conv (Conv  (None, 8, 8, 128)            106496    ['conv5_block11_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_1_bn (BatchN  (None, 8, 8, 128)            512       ['conv5_block11_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block11_1_relu (Acti  (None, 8, 8, 128)            0         ['conv5_block11_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block11_2_conv (Conv  (None, 8, 8, 32)             36864     ['conv5_block11_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_concat (Conc  (None, 8, 8, 864)            0         ['conv5_block10_concat[0][0]',\n",
      " atenate)                                                            'conv5_block11_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv5_block12_0_bn (BatchN  (None, 8, 8, 864)            3456      ['conv5_block11_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block12_0_relu (Acti  (None, 8, 8, 864)            0         ['conv5_block12_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block12_1_conv (Conv  (None, 8, 8, 128)            110592    ['conv5_block12_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_1_bn (BatchN  (None, 8, 8, 128)            512       ['conv5_block12_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block12_1_relu (Acti  (None, 8, 8, 128)            0         ['conv5_block12_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block12_2_conv (Conv  (None, 8, 8, 32)             36864     ['conv5_block12_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_concat (Conc  (None, 8, 8, 896)            0         ['conv5_block11_concat[0][0]',\n",
      " atenate)                                                            'conv5_block12_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv5_block13_0_bn (BatchN  (None, 8, 8, 896)            3584      ['conv5_block12_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block13_0_relu (Acti  (None, 8, 8, 896)            0         ['conv5_block13_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block13_1_conv (Conv  (None, 8, 8, 128)            114688    ['conv5_block13_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_1_bn (BatchN  (None, 8, 8, 128)            512       ['conv5_block13_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block13_1_relu (Acti  (None, 8, 8, 128)            0         ['conv5_block13_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block13_2_conv (Conv  (None, 8, 8, 32)             36864     ['conv5_block13_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_concat (Conc  (None, 8, 8, 928)            0         ['conv5_block12_concat[0][0]',\n",
      " atenate)                                                            'conv5_block13_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv5_block14_0_bn (BatchN  (None, 8, 8, 928)            3712      ['conv5_block13_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block14_0_relu (Acti  (None, 8, 8, 928)            0         ['conv5_block14_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block14_1_conv (Conv  (None, 8, 8, 128)            118784    ['conv5_block14_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_1_bn (BatchN  (None, 8, 8, 128)            512       ['conv5_block14_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block14_1_relu (Acti  (None, 8, 8, 128)            0         ['conv5_block14_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block14_2_conv (Conv  (None, 8, 8, 32)             36864     ['conv5_block14_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_concat (Conc  (None, 8, 8, 960)            0         ['conv5_block13_concat[0][0]',\n",
      " atenate)                                                            'conv5_block14_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv5_block15_0_bn (BatchN  (None, 8, 8, 960)            3840      ['conv5_block14_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block15_0_relu (Acti  (None, 8, 8, 960)            0         ['conv5_block15_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block15_1_conv (Conv  (None, 8, 8, 128)            122880    ['conv5_block15_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_1_bn (BatchN  (None, 8, 8, 128)            512       ['conv5_block15_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block15_1_relu (Acti  (None, 8, 8, 128)            0         ['conv5_block15_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block15_2_conv (Conv  (None, 8, 8, 32)             36864     ['conv5_block15_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_concat (Conc  (None, 8, 8, 992)            0         ['conv5_block14_concat[0][0]',\n",
      " atenate)                                                            'conv5_block15_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " conv5_block16_0_bn (BatchN  (None, 8, 8, 992)            3968      ['conv5_block15_concat[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block16_0_relu (Acti  (None, 8, 8, 992)            0         ['conv5_block16_0_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block16_1_conv (Conv  (None, 8, 8, 128)            126976    ['conv5_block16_0_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_1_bn (BatchN  (None, 8, 8, 128)            512       ['conv5_block16_1_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block16_1_relu (Acti  (None, 8, 8, 128)            0         ['conv5_block16_1_bn[0][0]']  \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block16_2_conv (Conv  (None, 8, 8, 32)             36864     ['conv5_block16_1_relu[0][0]']\n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_concat (Conc  (None, 8, 8, 1024)           0         ['conv5_block15_concat[0][0]',\n",
      " atenate)                                                            'conv5_block16_2_conv[0][0]']\n",
      "                                                                                                  \n",
      " bn (BatchNormalization)     (None, 8, 8, 1024)           4096      ['conv5_block16_concat[0][0]']\n",
      "                                                                                                  \n",
      " relu (Activation)           (None, 8, 8, 1024)           0         ['bn[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 1024)                 0         ['relu[0][0]']                \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  131200    ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 9)                    1161      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7169865 (27.35 MB)\n",
      "Trainable params: 132361 (517.04 KB)\n",
      "Non-trainable params: 7037504 (26.85 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import innvestigate\n",
    "\n",
    "model = innvestigate.model_wo_softmax(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LRP analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from innvestigate.analyzer import LRPSequentialPresetBFlat\n",
    "\n",
    "analyzer = LRPSequentialPresetBFlat(model, reverse_verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "img_path = \"../data/test/Bacterial Leaf Blight/aug_0_14.jpg\"\n",
    "img = image.load_img(img_path, target_size=(256, 256))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = preprocess_input(img_array)\n",
    "img_array = np.expand_dims(img_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Relevance Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverse model: <keras.src.engine.functional.Functional object at 0x000001F3D3BD41F0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\innvestigate\\backend\\graph.py:467: UserWarning: Ignore dtype <dtype: 'float32'> as bias type.\n",
      "  warnings.warn(f\"Ignore dtype {dtype} as bias type.\")\n",
      "c:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\innvestigate\\backend\\graph.py:480: UserWarning: Ignore dtype <dtype: 'float32'> as bias type.\n",
      "  warnings.warn(f\"Ignore dtype {dtype} as bias type.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NID: 429] Reverse layer-node <innvestigate.layers.MaxNeuronSelection object at 0x000001F3D61CFB80>\n",
      "[NID: 428] Reverse layer-node <keras.src.layers.core.dense.Dense object at 0x000001F3D61CF9D0>\n",
      "[NID: 427] Reverse layer-node <keras.src.layers.core.dense.Dense object at 0x000001F3D60C0610>\n",
      "[NID: 426] Reverse layer-node <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x000001F3CB80A260>\n",
      "[NID: 425] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D3B72B90>\n",
      "[NID: 424] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D3B72CE0>\n",
      "[NID: 423] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D2B4C2B0>\n",
      "[NID: 422] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D3B72A40>\n",
      "[NID: 421] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D2AE2B30>\n",
      "[NID: 420] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D3B41960>\n",
      "[NID: 419] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D2B4F490>\n",
      "[NID: 418] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D2AE2500>\n",
      "[NID: 417] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D2B4CBE0>\n",
      "[NID: 416] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D2ABA4A0>\n",
      "[NID: 415] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D2B16890>\n",
      "[NID: 414] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D2AB9720>\n",
      "[NID: 413] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D2AE3730>\n",
      "[NID: 412] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D2AE38E0>\n",
      "[NID: 411] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D29F2740>\n",
      "[NID: 410] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D2ABB0D0>\n",
      "[NID: 409] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D2A586D0>\n",
      "[NID: 408] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D2ABAE30>\n",
      "[NID: 407] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D29F1C00>\n",
      "[NID: 406] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D2A8DDB0>\n",
      "[NID: 405] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D2A5B8E0>\n",
      "[NID: 404] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D29F2FE0>\n",
      "[NID: 403] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D2A59000>\n",
      "[NID: 402] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D29CA830>\n",
      "[NID: 401] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D2A2ACE0>\n",
      "[NID: 400] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D2999B70>\n",
      "[NID: 399] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D29F3E20>\n",
      "[NID: 398] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D29F3970>\n",
      "[NID: 397] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D299A6B0>\n",
      "[NID: 396] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D29CB580>\n",
      "[NID: 395] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D2968B50>\n",
      "[NID: 394] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D29CB280>\n",
      "[NID: 393] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D296A2C0>\n",
      "[NID: 392] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D299A200>\n",
      "[NID: 391] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D296BD30>\n",
      "[NID: 390] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D290B130>\n",
      "[NID: 389] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D296BBB0>\n",
      "[NID: 388] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D29354E0>\n",
      "[NID: 387] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D2937160>\n",
      "[NID: 386] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D28AA0E0>\n",
      "[NID: 385] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D2909F30>\n",
      "[NID: 384] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D290ABC0>\n",
      "[NID: 383] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D2779D80>\n",
      "[NID: 382] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D28DB730>\n",
      "[NID: 381] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D2884FD0>\n",
      "[NID: 380] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D28DAEF0>\n",
      "[NID: 379] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D267BB50>\n",
      "[NID: 378] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D28AAE90>\n",
      "[NID: 377] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D28AA950>\n",
      "[NID: 376] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D2884E20>\n",
      "[NID: 375] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D28858A0>\n",
      "[NID: 374] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D2856CB0>\n",
      "[NID: 373] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D2827EB0>\n",
      "[NID: 372] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D2857730>\n",
      "[NID: 371] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D2826890>\n",
      "[NID: 370] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D2827C40>\n",
      "[NID: 369] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D2827160>\n",
      "[NID: 368] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D2826980>\n",
      "[NID: 367] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D27FE3E0>\n",
      "[NID: 366] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D27FE020>\n",
      "[NID: 365] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D27D4A90>\n",
      "[NID: 364] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D27D4610>\n",
      "[NID: 363] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D27D4C10>\n",
      "[NID: 362] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D27ABF70>\n",
      "[NID: 361] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D27AB850>\n",
      "[NID: 360] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D277B3D0>\n",
      "[NID: 359] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D277B0A0>\n",
      "[NID: 358] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D2751630>\n",
      "[NID: 357] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D2751BD0>\n",
      "[NID: 356] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D2751A80>\n",
      "[NID: 355] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D2726E30>\n",
      "[NID: 354] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D2724760>\n",
      "[NID: 353] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D26FB9D0>\n",
      "[NID: 352] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D26FBC10>\n",
      "[NID: 351] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D26DA3E0>\n",
      "[NID: 350] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D26DA980>\n",
      "[NID: 349] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D26DA830>\n",
      "[NID: 348] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D26D9B70>\n",
      "[NID: 347] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D26D9390>\n",
      "[NID: 346] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D26A8C10>\n",
      "[NID: 345] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D267BAC0>\n",
      "[NID: 344] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D2656FE0>\n",
      "[NID: 343] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D2657730>\n",
      "[NID: 342] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D26575E0>\n",
      "[NID: 341] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D2656AA0>\n",
      "[NID: 340] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D2656200>\n",
      "[NID: 339] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D1651D80>\n",
      "[NID: 338] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D1651A50>\n",
      "[NID: 337] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D1623280>\n",
      "[NID: 336] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D1623D00>\n",
      "[NID: 335] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D15F2140>\n",
      "[NID: 334] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D15F3730>\n",
      "[NID: 333] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D15F2EC0>\n",
      "[NID: 332] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D15DABF0>\n",
      "[NID: 331] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D15DA8C0>\n",
      "[NID: 330] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D15A0DC0>\n",
      "[NID: 329] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D15A1360>\n",
      "[NID: 328] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D15A1210>\n",
      "[NID: 327] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D1573640>\n",
      "[NID: 326] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D1573D30>\n",
      "[NID: 325] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D15539A0>\n",
      "[NID: 324] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D15534C0>\n",
      "[NID: 323] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D1525AB0>\n",
      "[NID: 322] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D1526110>\n",
      "[NID: 321] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D1525FC0>\n",
      "[NID: 320] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D1525A20>\n",
      "[NID: 319] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D1524850>\n",
      "[NID: 318] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D14F7BE0>\n",
      "[NID: 317] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D14CEC80>\n",
      "[NID: 316] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D14AA9E0>\n",
      "[NID: 315] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D14AAF80>\n",
      "[NID: 314] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D14AAE30>\n",
      "[NID: 313] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D14AA7A0>\n",
      "[NID: 312] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D14A89A0>\n",
      "[NID: 311] Reverse layer-node <keras.src.layers.pooling.average_pooling2d.AveragePooling2D object at 0x000001F3D14812D0>\n",
      "[NID: 310] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D1481180>\n",
      "[NID: 309] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D14576A0>\n",
      "[NID: 308] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D14571F0>\n",
      "[NID: 307] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D142B4F0>\n",
      "[NID: 306] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D142B1C0>\n",
      "[NID: 305] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D13F9540>\n",
      "[NID: 304] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D13F9AB0>\n",
      "[NID: 303] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D13F9C30>\n",
      "[NID: 302] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D13F9420>\n",
      "[NID: 301] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D13D7970>\n",
      "[NID: 300] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D13A3CD0>\n",
      "[NID: 299] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D13A3D00>\n",
      "[NID: 298] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D138B040>\n",
      "[NID: 297] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D138AA10>\n",
      "[NID: 296] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D138A8C0>\n",
      "[NID: 295] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D1389D80>\n",
      "[NID: 294] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D13894E0>\n",
      "[NID: 293] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D13547F0>\n",
      "[NID: 292] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D12F7550>\n",
      "[NID: 291] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D132B520>\n",
      "[NID: 290] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D132BAF0>\n",
      "[NID: 289] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D12F76D0>\n",
      "[NID: 288] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D12F6A10>\n",
      "[NID: 287] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D12F5C30>\n",
      "[NID: 286] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D125B220>\n",
      "[NID: 285] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D12D9C00>\n",
      "[NID: 284] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D12ABC70>\n",
      "[NID: 283] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D12A8E20>\n",
      "[NID: 282] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D127B820>\n",
      "[NID: 281] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D127B880>\n",
      "[NID: 280] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D127B0A0>\n",
      "[NID: 279] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D125AB00>\n",
      "[NID: 278] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D125A740>\n",
      "[NID: 277] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D122CD30>\n",
      "[NID: 276] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D122D480>\n",
      "[NID: 275] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D122D330>\n",
      "[NID: 274] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D11FFD30>\n",
      "[NID: 273] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D11FFF10>\n",
      "[NID: 272] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D11DBB50>\n",
      "[NID: 271] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D11DB820>\n",
      "[NID: 270] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D11A5DB0>\n",
      "[NID: 269] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D11A6350>\n",
      "[NID: 268] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D11A6200>\n",
      "[NID: 267] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3D11A5B70>\n",
      "[NID: 266] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3D11A4CD0>\n",
      "[NID: 265] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3D1187F70>\n",
      "[NID: 264] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3D094F400>\n",
      "[NID: 263] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3CF886B30>\n",
      "[NID: 262] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3CF8870D0>\n",
      "[NID: 261] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3CF886F80>\n",
      "[NID: 260] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3CF8862C0>\n",
      "[NID: 259] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3CF885AE0>\n",
      "[NID: 258] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3CE2CCC70>\n",
      "[NID: 257] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3CE272320>\n",
      "[NID: 256] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3CE29FB80>\n",
      "[NID: 255] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3CE09EC50>\n",
      "[NID: 254] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3CE050B80>\n",
      "[NID: 253] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3CE0D4D60>\n",
      "[NID: 252] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3CE01D5A0>\n",
      "[NID: 251] Reverse layer-node <keras.src.layers.merging.concatenate.Concatenate object at 0x000001F3CDE76B30>\n",
      "[NID: 250] Reverse layer-node <keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001F3CCDF5E10>\n",
      "[NID: 249] Reverse layer-node <keras.src.layers.core.activation.Activation object at 0x000001F3CDE229E0>\n",
      "[NID: 248] Reverse layer-node <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3CCCAA290>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get relevance heatmap\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m relevance \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\innvestigate\\analyzer\\network_base.py:250\u001b[0m, in \u001b[0;36mAnalyzerNetworkBase.analyze\u001b[1;34m(self, X, neuron_selection)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# TODO: what does should mean in docstring?\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_analyzer_model_done \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_analyzer_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neuron_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neuron_selection_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneuron_selection_mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neuron_selection_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneuron_selection\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    256\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\innvestigate\\analyzer\\network_base.py:164\u001b[0m, in \u001b[0;36mAnalyzerNetworkBase.create_analyzer_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_analysis_inputs \u001b[38;5;241m=\u001b[39m analysis_inputs\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepared_model \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 164\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_analysis_at_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop_analysis_at_tensors\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tmp, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tmp) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\innvestigate\\analyzer\\relevance_based\\relevance_analyzer.py:490\u001b[0m, in \u001b[0;36mLRP._create_analysis\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_conditional_reverse_mapping(\n\u001b[0;32m    484\u001b[0m     ichecks\u001b[38;5;241m.\u001b[39mis_embedding_layer,\n\u001b[0;32m    485\u001b[0m     EmbeddingReverseLayer,\n\u001b[0;32m    486\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlrp_embedding_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    487\u001b[0m )\n\u001b[0;32m    489\u001b[0m \u001b[38;5;66;03m# FINALIZED constructor.\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_create_analysis(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\innvestigate\\analyzer\\reverse_base.py:268\u001b[0m, in \u001b[0;36mReverseAnalyzerBase._create_analysis\u001b[1;34m(self, model, stop_analysis_at_tensors)\u001b[0m\n\u001b[0;32m    260\u001b[0m return_all_reversed_tensors \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reverse_check_min_max_values\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reverse_check_finite\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reverse_keep_tensors\n\u001b[0;32m    264\u001b[0m )\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# if return_all_reversed_tensors is False,\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# reversed_tensors will be None\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m reversed_input_tensors, reversed_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reverse_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop_analysis_at_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop_analysis_at_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_all_reversed_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_all_reversed_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postprocess_analysis(reversed_input_tensors)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_all_reversed_tensors:\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\innvestigate\\analyzer\\reverse_base.py:242\u001b[0m, in \u001b[0;36mReverseAnalyzerBase._reverse_model\u001b[1;34m(self, model, stop_analysis_at_tensors, return_all_reversed_tensors)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_analysis_at_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     stop_analysis_at_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43migraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreverse_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreverse_mappings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reverse_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_reverse_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_reverse_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_head_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop_mapping_at_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop_analysis_at_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reverse_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip_all_reversed_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reverse_clip_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_bottleneck_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reverse_project_bottleneck_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_all_reversed_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_all_reversed_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\innvestigate\\backend\\graph.py:1253\u001b[0m, in \u001b[0;36mreverse_model\u001b[1;34m(model, reverse_mappings, default_reverse_mapping, head_mapping, stop_mapping_at_tensors, verbose, return_all_reversed_tensors, clip_all_reversed_tensors, project_bottleneck_tensors, execution_trace, reapply_on_copied_layers)\u001b[0m\n\u001b[0;32m   1251\u001b[0m _print(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[NID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Reverse layer-node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1252\u001b[0m reverse_mapping \u001b[38;5;241m=\u001b[39m initialized_reverse_mappings[layer]\n\u001b[1;32m-> 1253\u001b[0m reversed_Xs \u001b[38;5;241m=\u001b[39m \u001b[43mreverse_mapping\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mYs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreversed_Ys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m   1258\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop_mapping_at_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_stop_mapping_at_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1264\u001b[0m reversed_Xs \u001b[38;5;241m=\u001b[39m ibackend\u001b[38;5;241m.\u001b[39mto_list(reversed_Xs)\n\u001b[0;32m   1265\u001b[0m add_reversed_tensors(nid, Xs, reversed_Xs)\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\innvestigate\\analyzer\\relevance_based\\relevance_rule.py:414\u001b[0m, in \u001b[0;36mAlphaBetaXRule.apply\u001b[1;34m(self, Xs, _Ys, Rs, _reverse_state)\u001b[0m\n\u001b[0;32m    412\u001b[0m r_pn \u001b[38;5;241m=\u001b[39m fn_tmp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layer_wo_act_negative, Xs_pos)\n\u001b[0;32m    413\u001b[0m \u001b[38;5;66;03m# xneg*wpos\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m r_np \u001b[38;5;241m=\u001b[39m \u001b[43mfn_tmp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_layer_wo_act_positive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXs_neg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# b0 * r_pn + b1 * r_np\u001b[39;00m\n\u001b[0;32m    416\u001b[0m r_neg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    417\u001b[0m     klayers\u001b[38;5;241m.\u001b[39mAdd()([times_beta0(pn), times_beta1(np)])\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pn, np \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(r_pn, r_np)\n\u001b[0;32m    419\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\innvestigate\\analyzer\\relevance_based\\relevance_rule.py:395\u001b[0m, in \u001b[0;36mAlphaBetaXRule.apply.<locals>.fn_tmp\u001b[1;34m(layer, Xs)\u001b[0m\n\u001b[0;32m    393\u001b[0m grads \u001b[38;5;241m=\u001b[39m ibackend\u001b[38;5;241m.\u001b[39mgradients(Xs, Zs, tmp)\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# Re-weight relevance with the input values.\u001b[39;00m\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [klayers\u001b[38;5;241m.\u001b[39mMultiply()([a, b]) \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(Xs, grads)]\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\innvestigate\\analyzer\\relevance_based\\relevance_rule.py:395\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    393\u001b[0m grads \u001b[38;5;241m=\u001b[39m ibackend\u001b[38;5;241m.\u001b[39mgradients(Xs, Zs, tmp)\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# Re-weight relevance with the input values.\u001b[39;00m\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mklayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(Xs, grads)]\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_v1.py:798\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;66;03m# Only create Keras history if at least one tensor originates from a\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;66;03m# `keras.Input`. Otherwise this Layer may be being used outside the\u001b[39;00m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;66;03m# Keras framework.\u001b[39;00m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m build_graph \u001b[38;5;129;01mand\u001b[39;00m base_layer_utils\u001b[38;5;241m.\u001b[39mneeds_keras_history(inputs):\n\u001b[1;32m--> 798\u001b[0m     \u001b[43mbase_layer_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_keras_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\u001b[38;5;28mself\u001b[39m, inputs, build_graph, training_value):\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input\u001b[39;00m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;66;03m# shape.\u001b[39;00m\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m build_graph:\n\u001b[0;32m    804\u001b[0m         \u001b[38;5;66;03m# Symbolic execution on symbolic tensors. We will attempt to\u001b[39;00m\n\u001b[0;32m    805\u001b[0m         \u001b[38;5;66;03m# build the corresponding TF subgraph inside\u001b[39;00m\n\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m# `backend.get_graph()`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:211\u001b[0m, in \u001b[0;36mcreate_keras_history\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_keras_history\u001b[39m(tensors):\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wraps TensorFlow Operations for compatibility with the Functional API.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m    This method checks to see if a Tensor in `tensors` is missing Keras metadata\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m        the raw Tensorflow operations.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m     _, created_layers \u001b[38;5;241m=\u001b[39m \u001b[43m_create_keras_history_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m created_layers\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:297\u001b[0m, in \u001b[0;36m_create_keras_history_helper\u001b[1;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[0;32m    295\u001b[0m                 constants[i] \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfunction([], op_input)([])\n\u001b[0;32m    296\u001b[0m layer_inputs \u001b[38;5;241m=\u001b[39m unnest_if_single_tensor(layer_inputs)\n\u001b[1;32m--> 297\u001b[0m processed_ops, created_layers \u001b[38;5;241m=\u001b[39m \u001b[43m_create_keras_history_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreated_layers\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m name \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    301\u001b[0m node_def \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mnode_def\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:297\u001b[0m, in \u001b[0;36m_create_keras_history_helper\u001b[1;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[0;32m    295\u001b[0m                 constants[i] \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfunction([], op_input)([])\n\u001b[0;32m    296\u001b[0m layer_inputs \u001b[38;5;241m=\u001b[39m unnest_if_single_tensor(layer_inputs)\n\u001b[1;32m--> 297\u001b[0m processed_ops, created_layers \u001b[38;5;241m=\u001b[39m \u001b[43m_create_keras_history_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreated_layers\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m name \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    301\u001b[0m node_def \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mnode_def\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "    \u001b[1;31m[... skipping similar frames: _create_keras_history_helper at line 297 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:297\u001b[0m, in \u001b[0;36m_create_keras_history_helper\u001b[1;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[0;32m    295\u001b[0m                 constants[i] \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfunction([], op_input)([])\n\u001b[0;32m    296\u001b[0m layer_inputs \u001b[38;5;241m=\u001b[39m unnest_if_single_tensor(layer_inputs)\n\u001b[1;32m--> 297\u001b[0m processed_ops, created_layers \u001b[38;5;241m=\u001b[39m \u001b[43m_create_keras_history_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreated_layers\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m name \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    301\u001b[0m node_def \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mnode_def\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:295\u001b[0m, in \u001b[0;36m_create_keras_history_helper\u001b[1;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[1;32m--> 295\u001b[0m                 constants[i] \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m layer_inputs \u001b[38;5;241m=\u001b[39m unnest_if_single_tensor(layer_inputs)\n\u001b[0;32m    297\u001b[0m processed_ops, created_layers \u001b[38;5;241m=\u001b[39m _create_keras_history_helper(\n\u001b[0;32m    298\u001b[0m     layer_inputs, processed_ops, created_layers\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:4607\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4598\u001b[0m \u001b[38;5;66;03m# Refresh callable if anything has changed.\u001b[39;00m\n\u001b[0;32m   4599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4600\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4601\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4605\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[0;32m   4606\u001b[0m ):\n\u001b[1;32m-> 4607\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeed_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_symbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4609\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn(\u001b[38;5;241m*\u001b[39marray_vals, run_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_metadata)\n\u001b[0;32m   4610\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:4532\u001b[0m, in \u001b[0;36mGraphExecutionFunction._make_callable\u001b[1;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[0;32m   4530\u001b[0m     callable_opts\u001b[38;5;241m.\u001b[39mrun_options\u001b[38;5;241m.\u001b[39mCopyFrom(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_options)\n\u001b[0;32m   4531\u001b[0m \u001b[38;5;66;03m# Create callable.\u001b[39;00m\n\u001b[1;32m-> 4532\u001b[0m callable_fn \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_callable_from_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallable_opts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4533\u001b[0m \u001b[38;5;66;03m# Cache parameters corresponding to the generated callable, so that\u001b[39;00m\n\u001b[0;32m   4534\u001b[0m \u001b[38;5;66;03m# we can detect future mismatches and refresh the callable.\u001b[39;00m\n\u001b[0;32m   4535\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;241m=\u001b[39m callable_fn\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1537\u001b[0m, in \u001b[0;36mBaseSession._make_callable_from_options\u001b[1;34m(self, callable_options)\u001b[0m\n\u001b[0;32m   1527\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_make_callable_from_options\u001b[39m(\u001b[38;5;28mself\u001b[39m, callable_options):\n\u001b[0;32m   1528\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a handle to a \"callable\" with the given options.\u001b[39;00m\n\u001b[0;32m   1529\u001b[0m \n\u001b[0;32m   1530\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1535\u001b[0m \u001b[38;5;124;03m    A handle to the new callable.\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1537\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extend_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1538\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m BaseSession\u001b[38;5;241m.\u001b[39m_Callable(\u001b[38;5;28mself\u001b[39m, callable_options)\n",
      "File \u001b[1;32mc:\\Users\\steam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1425\u001b[0m, in \u001b[0;36mBaseSession._extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_extend_graph\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1424\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39m_session_run_lock():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1425\u001b[0m     \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExtendSession\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "relevance = analyzer.analyze(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRP Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Aggregate along color channels and normalize to [-1, 1]\n",
    "relevance_visualization = relevance.sum(axis=np.argmax(np.asarray(relevance.shape) == 3))\n",
    "relevance_visualization /= np.max(np.abs(relevance_visualization))\n",
    "\n",
    "# Plot\n",
    "plt.imshow(relevance_visualization[0], cmap=\"seismic\", clim=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
